{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCXqYUU_GLCc",
        "outputId": "70ffde09-983d-4959-bc9b-afa5c6d200e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Define the improved CNN with Batch Normalization\n",
        "def improved_cnn_with_bn():\n",
        "    model = models.Sequential([\n",
        "        # Block 1\n",
        "        layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(32, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Block 2\n",
        "        layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Block 3\n",
        "        layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        # Dense Layers\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 3. Compile and train the model\n",
        "model = improved_cnn_with_bn()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "# 4. Evaluate accuracy\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\" Test Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TSyMlV3GOW1",
        "outputId": "36941a04-f819-4472-d156-564177fb9e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.3789 - loss: 1.8305 - val_accuracy: 0.3465 - val_loss: 2.3236\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.6150 - loss: 1.0662 - val_accuracy: 0.6229 - val_loss: 1.0851\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.6892 - loss: 0.8788 - val_accuracy: 0.5744 - val_loss: 1.3161\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7298 - loss: 0.7716 - val_accuracy: 0.7276 - val_loss: 0.8019\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7587 - loss: 0.6926 - val_accuracy: 0.7511 - val_loss: 0.7294\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7765 - loss: 0.6367 - val_accuracy: 0.7322 - val_loss: 0.7866\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7932 - loss: 0.5928 - val_accuracy: 0.7950 - val_loss: 0.5965\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.8008 - loss: 0.5610 - val_accuracy: 0.7893 - val_loss: 0.6188\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8191 - loss: 0.5188 - val_accuracy: 0.8042 - val_loss: 0.5691\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8255 - loss: 0.4927 - val_accuracy: 0.8158 - val_loss: 0.5357\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8332 - loss: 0.4732 - val_accuracy: 0.7851 - val_loss: 0.6359\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8456 - loss: 0.4453 - val_accuracy: 0.8307 - val_loss: 0.4952\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8551 - loss: 0.4162 - val_accuracy: 0.7691 - val_loss: 0.7158\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8614 - loss: 0.3942 - val_accuracy: 0.8474 - val_loss: 0.4646\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8629 - loss: 0.3889 - val_accuracy: 0.8320 - val_loss: 0.5053\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8695 - loss: 0.3711 - val_accuracy: 0.8239 - val_loss: 0.5374\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8749 - loss: 0.3545 - val_accuracy: 0.8443 - val_loss: 0.4652\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8802 - loss: 0.3447 - val_accuracy: 0.8378 - val_loss: 0.4921\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8797 - loss: 0.3357 - val_accuracy: 0.8427 - val_loss: 0.4730\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8831 - loss: 0.3300 - val_accuracy: 0.8516 - val_loss: 0.4465\n",
            " Test Accuracy: 0.8516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Reduce dataset for speed (optional)\n",
        "x_train, y_train = x_train[:5000], y_train[:5000]\n",
        "x_test, y_test = x_test[:1000], y_test[:1000]\n",
        "\n",
        "# Preprocess and resize\n",
        "x_train = tf.image.resize(x_train, [224, 224])\n",
        "x_test = tf.image.resize(x_test, [224, 224])\n",
        "x_train = preprocess_input(x_train)\n",
        "\n",
        "x_test = preprocess_input(x_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpbNKGWZK-sL",
        "outputId": "39d7941f-4cec-4d5c-8dcf-f28bbb4c2e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base ResNet50 (frozen)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze all layers\n",
        "\n",
        "# Add custom head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile & train\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\" Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sb1f5L6d17-",
        "outputId": "2ba9fbc3-bea3-44e7-9c23-1f00d6d893f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 184ms/step - accuracy: 0.5783 - loss: 1.2687 - val_accuracy: 0.8600 - val_loss: 0.4549\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 103ms/step - accuracy: 0.8870 - loss: 0.3502 - val_accuracy: 0.8750 - val_loss: 0.3792\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 126ms/step - accuracy: 0.9245 - loss: 0.2412 - val_accuracy: 0.8670 - val_loss: 0.3859\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 109ms/step - accuracy: 0.9422 - loss: 0.1908 - val_accuracy: 0.8710 - val_loss: 0.3778\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 130ms/step - accuracy: 0.9599 - loss: 0.1504 - val_accuracy: 0.8810 - val_loss: 0.3646\n",
            " Test Accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparison: Custom CNN vs ResNet50 on CIFAR-10\n",
        "| **Aspect**              | **Custom CNN (from scratch)**                       | **ResNet50 (transfer learning)**                    |\n",
        "| ----------------------- | --------------------------------------------------- | --------------------------------------------------- |\n",
        "| **Architecture**        | Manually designed with Conv layers, BatchNorm, etc. | Pre-trained ResNet50 base + custom classifier head  |\n",
        "| **Input Image Size**    | 32×32                                               | Resized to 224×224                                  |\n",
        "| **Training Time**       | Relatively fast (smaller model)                     | Slower (due to larger model & resizing overhead)    |\n",
        "| **Accuracy (Test Set)** | 85.16%                                           | 87.50%            |\n",
        "| **Resource Usage**      | Lightweight – good for limited GPU/CPU              | Heavy – requires more memory and compute            |\n",
        "| **Flexibility**         | Fully controllable and modifiable                   | Less flexible (pre-defined layers, limited edits)   |\n",
        "| **Best For**            | Learning, experimentation, lightweight deployment   | Higher accuracy on small datasets, production-ready |\n",
        "\n",
        "Summary:\n",
        "\n",
        "The Custom CNN is faster and resource-efficient, making it great for learning, prototyping, and lower-end hardware.\n",
        "\n",
        "ResNet50 provides better accuracy due to its deep pre-trained architecture, but at the cost of higher computational demands and training time."
      ],
      "metadata": {
        "id": "FwNLxK0RpWJQ"
      }
    }
  ]
}